{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XtxiUeZEiXpt"},"outputs":[],"source":["import numpy as np\n","import os\n","import pycocotools\n","import tqdm as notebook_tqdm\n","import tensorflow as tf\n","assert tf.__version__.startswith('2')\n","\n","import tflite_model_maker\n","\n","from tflite_model_maker.config import ExportFormat\n","from tflite_model_maker import model_spec\n","from tflite_model_maker import object_detector\n","\n","tf.get_logger().setLevel('ERROR')\n","from absl import logging\n","logging.set_verbosity(logging.ERROR)\n","\n","print(tf.__version__)\n","print(tflite_model_maker.__version__)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"87SWzZJF4YcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tflite_model_maker"],"metadata":{"id":"4FOWu2W-8qvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6Z35Hr4NVPm"},"outputs":[],"source":["images_in = './oimage/'\n","annotations_in = './xml/'"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"wVQ2VQu7MuQa"},"outputs":[],"source":["\n","import os\n","import random\n","import shutil\n","\n","def split_dataset(images_path, annotations_path, val_split, test_split, out_path):\n","    \n","    \n","    \"\"\"將已排序的圖像/註釋目錄拆分為訓練、驗證和測試集。\n","\n","    參數：\n","    images_path：包含您的圖像 (JPG) 的目錄的路徑。\n","    annotations_path：您的 VOC XML 註釋文件的目錄路徑，\n","      與圖像文件名對應的文件名。這可能是相同的路徑\n","      用於圖像路徑。\n","    val_split：保留用於驗證的數據部分（在 0 和 1 之間浮動）。\n","    test_split：為測試保留的數據部分（在 0 和 1 之間浮動）。\n","    返回：\n","    分割圖像/註釋的路徑（train_dir、val_dir、test_dir）\n","    \"\"\"\n","    _, dirs, _ = next(os.walk(images_path))                       #查看路徑\n","\n","    train_dir = os.path.join(out_path, 'train')\n","    val_dir = os.path.join(out_path, 'validation')\n","    test_dir = os.path.join(out_path, 'test')\n","\n","    IMAGES_TRAIN_DIR = os.path.join(train_dir, 'images')\n","    IMAGES_VAL_DIR = os.path.join(val_dir, 'images')\n","    IMAGES_TEST_DIR = os.path.join(test_dir, 'images')\n","    os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n","    os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n","    os.makedirs(IMAGES_TEST_DIR, exist_ok=True)\n","\n","    ANNOT_TRAIN_DIR = os.path.join(train_dir, 'annotations')\n","    ANNOT_VAL_DIR = os.path.join(val_dir, 'annotations')\n","    ANNOT_TEST_DIR = os.path.join(test_dir, 'annotations')\n","    os.makedirs(ANNOT_TRAIN_DIR, exist_ok=True)\n","    os.makedirs(ANNOT_VAL_DIR, exist_ok=True)\n","    os.makedirs(ANNOT_TEST_DIR, exist_ok=True)\n","\n","    # Get all filenames for this dir, filtered by filetype\n","    filenames = os.listdir(os.path.join(images_path))\n","    filenames = [os.path.join(images_path, f) for f in filenames if (f.endswith('.jpg'))]\n","    # Shuffle the files, deterministically\n","    filenames.sort()\n","    random.seed(42)\n","    random.shuffle(filenames)\n","    # Get exact number of images for validation and test; the rest is for training\n","    val_count = int(len(filenames) * val_split)\n","    test_count = int(len(filenames) * test_split)\n","    for i, file in enumerate(filenames):\n","        source_dir, filename = os.path.split(file)\n","        annot_file = os.path.join(annotations_path, filename.replace(\"jpg\", \"xml\"))\n","        if i < val_count:\n","            shutil.copy(file, IMAGES_VAL_DIR)\n","            shutil.copy(annot_file, ANNOT_VAL_DIR)\n","        elif i < val_count + test_count:\n","            shutil.copy(file, IMAGES_TEST_DIR)\n","            shutil.copy(annot_file, ANNOT_TEST_DIR)\n","        else:\n","            shutil.copy(file, IMAGES_TRAIN_DIR)\n","            shutil.copy(annot_file, ANNOT_TRAIN_DIR)\n","    return (train_dir, val_dir, test_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Gw3YQpXNVPo"},"outputs":[],"source":["train_dir, val_dir, test_dir = split_dataset(images_in, annotations_in,\n","                                             val_split=0.2, test_split=0.2,\n","                                             out_path='new_split-dataset_2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mz_suhWiqc7A"},"outputs":[],"source":["label_map= [\"M\", \"K\", \"S\"]\n","train_images_dir = './new_split-dataset_2/train/images/'\n","train_annotations_dir = './new_split-dataset_2/train/annotations'\n","val_images_dir = './new_split-dataset_2/validation/images/'\n","val_annotations_dir = './new_split-dataset_2/validation/annotations'\n","test_images_dir = './new_split-dataset_2/test/images/'\n","test_annotations_dir = './new_split-dataset_2/test/annotations'"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"C35meprE8xzf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-rEdfkcNVPp"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWROlVNA54xZ","scrolled":true},"outputs":[],"source":["\n","train_data = object_detector.DataLoader.from_pascal_voc(\n","    train_images_dir, train_annotations_dir, label_map=label_map, cache_dir=\"./cache_data_ta/train\", num_shards=1, max_num_images=3000)\n","\n","validation_data = object_detector.DataLoader.from_pascal_voc(\n","    val_images_dir, val_annotations_dir, label_map=label_map, cache_dir=\"./cache_data_ta/validation\",num_shards=1, max_num_images=1000)\n","\n","test_data = object_detector.DataLoader.from_pascal_voc(\n","   test_images_dir, test_annotations_dir, label_map=label_map, cache_dir=\"./cache_data_ta/test\",num_shards=1, max_num_images=1000)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":[],"id":"Xg6oSnJoNVPq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3w3LauZoNVPq"},"outputs":[],"source":["train_data = object_detector.DataLoader.from_cache('./cache_data_ta/train/4bcdd345de559c097bc3f19ecc95ac13')\n","validation_data = object_detector.DataLoader.from_cache('./cache_data_ta/validation/4bcdd345de559c097bc3f19ecc95ac13')\n","test_data = object_detector.DataLoader.from_cache('./cache_data_ta/test/4bcdd345de559c097bc3f19ecc95ac13')\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8d57ZG6NVPq"},"outputs":[],"source":["print(f'train count: {len(train_data)}')\n","print(f'validation count: {len(validation_data)}')\n","print(f'test count: {len(test_data)}')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"S8clx0KPutCM"},"source":["## Select the model spec"]},{"cell_type":"markdown","metadata":{"id":"vn61LJ9QbOPi"},"source":["Model Maker supports the EfficientDet-Lite family of object detection models that are compatible with the Edge TPU. (EfficientDet-Lite is derived from [EfficientDet](https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html), which offers state-of-the-art accuracy in a small model size). There are several model sizes you can choose from:\n","\n","|| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n","|-|--------------------|-----------|---------------|----------------------|\n","|| EfficientDet-Lite0 | 5.7       | 37.4            | 30.4%               |\n","|| EfficientDet-Lite1 | 7.6       | 56.3            | 34.3%               |\n","|| EfficientDet-Lite2 | 10.2      | 104.6           | 36.0%               |\n","|| EfficientDet-Lite3 | 14.4      | 107.6           | 39.4%               |\n","| <td colspan=4><br><i>* File size of the compiled Edge TPU models. <br/>** Latency measured on a desktop CPU with a Coral USB Accelerator. <br/>*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.</i></td> |\n","\n","Beware that the Lite2 and Lite3 models do not fit onto the Edge TPU's onboard memory, so you'll see even greater latency when using those, due to the cost of fetching data from the host system memory. Maybe this extra latency is okay for your application, but if it's not and you require the precision of the larger models, then you can [pipeline the model across multiple Edge TPUs](https://coral.ai/docs/edgetpu/pipeline/) (more about this when we compile the model below).\n","\n","For this tutorial, we'll use Lite0:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SM9gePHw9Jv1"},"outputs":[],"source":["  spec = object_detector.EfficientDetLite0Spec()"]},{"cell_type":"markdown","metadata":{"id":"rnCzdzs0-Rbo"},"source":["The [`EfficientDetLite0Spec`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/EfficientDetLite0Spec) constructor also supports several arguments that specify training options, such as the max number of detections (default is 25 for the TF Lite model) and whether to use Cloud TPUs for training. You can also use the constructor to specify the number of training epochs and the batch size, but you can also specify those in the next step."]},{"cell_type":"markdown","metadata":{"id":"5qjq2UEHCLUi"},"source":["## Create and train the model"]},{"cell_type":"markdown","metadata":{"id":"2uZkLR6N6gDR"},"source":["Now we need to create our model according to the model spec, load our dataset into the model, specify training parameters, and begin training. \n","\n","Using Model Maker, we accomplished all of that with [`create()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/create):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwlYdTcg63xy","scrolled":true,"tags":[]},"outputs":[],"source":["model = object_detector.create(train_data=train_data, \n","                               model_spec=spec, \n","                               validation_data=validation_data, \n","                               epochs=200, \n","                               batch_size=16, \n","                               train_whole_model=True,\n","                               do_train=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ml-zDd5NVPt"},"outputs":[],"source":["#model.model.save_weights('./weights/2000.tf')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQyqmwrWNVPt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"3n5-o3vvGfnJ"},"source":["## Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xmnl6Yy7ARn"},"outputs":[],"source":["model.evaluate(test_data)"]},{"cell_type":"markdown","metadata":{"id":"_yB_XMpqGlLs"},"source":["## Export to TensorFlow Lite"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Cu9cxX5Qu-e"},"outputs":[],"source":["TFLITE_FILENAME = 'efficientdet.tflite'\n","LABELS_FILENAME = 'labels.txt'\n","SAVED_FILENAME = 'model'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKd6qk7TbxYO"},"outputs":[],"source":["model.export(export_dir='./export', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME, saved_model_filename=SAVED_FILENAME,\n","             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL, ExportFormat.SAVED_MODEL])"]},{"cell_type":"markdown","metadata":{"id":"b94hZ-exOCRB","tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"id":"ZQpahAIBqBPp"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RS3Ell_lqH4e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-hX-eEhNVPu"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Ph88z7PdOeX7"},"source":[]},{"cell_type":"markdown","metadata":{"id":"me6_RwPZqNhX"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eag7jTOASGFW"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZBecI78ZaxsO"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TmgtGBqua1N3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkXtipXKqXp4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"oxgWQyYOqZha"},"source":[]},{"cell_type":"markdown","metadata":{"id":"A0QLiwCj9Pw6"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oy3QIn_YqaRP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qRWewhqFqeL_"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZdonJGCqieU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"O2CjkduY02DF","tags":[]},"source":[]},{"cell_type":"markdown","metadata":{"id":"KyBBvyqx0XRn","tags":[]},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M43URVgg0ZcB"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8fYwl4Rt8myF"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Dv2Ingvx8pcI"},"source":[]},{"cell_type":"markdown","metadata":{"id":"HS4u77W5gnzQ"},"source":[]}],"metadata":{"colab":{"collapsed_sections":["license"],"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}